"""
æ·±åº¦æ„ŸçŸ¥æ¨¡å—
åŸºäºå¤–å‚æ ‡å®šå’Œæ·±åº¦ä¼ æ„Ÿçš„éšœç¢ç‰©å ç”¨æ£€æµ‹

æ ¸å¿ƒæ¦‚å¿µï¼š
1. Extrinsic Calibration: å®šä¹‰ç›¸æœºåœ¨æœºå™¨äººæœ«ç«¯çš„ä½ç½®å’Œå§¿æ€
2. Depth Sensing: ä½¿ç”¨æ·±åº¦ç›¸æœºè·å–æ·±åº¦å›¾åƒ
3. Occupancy Detection: å°†æ·±åº¦ä¿¡æ¯è½¬æ¢ä¸ºéšœç¢ç‰©ä½ç½®
"""

import pybullet as p
import numpy as np
from typing import List, Tuple, Optional, Dict


class DepthCamera:
    """
    æ·±åº¦ç›¸æœºç±»
    è´Ÿè´£å¤–å‚æ ‡å®šå’Œæ·±åº¦å›¾åƒè·å–
    """
    
    def __init__(self, 
                 robot_id: int,
                 sensor_link_id: int,
                 image_width: int = 128,
                 image_height: int = 128,
                 fov: float = 60.0,
                 near_plane: float = 0.01,
                 far_plane: float = 2.0):
        """
        åˆå§‹åŒ–æ·±åº¦ç›¸æœº
        
        Args:
            robot_id: æœºå™¨äººID
            sensor_link_id: ä¼ æ„Ÿå™¨è¿æ¥çš„link IDï¼ˆé€šå¸¸æ˜¯æœ«ç«¯æ‰§è¡Œå™¨ï¼‰
            image_width: å›¾åƒå®½åº¦ï¼ˆåƒç´ ï¼‰
            image_height: å›¾åƒé«˜åº¦ï¼ˆåƒç´ ï¼‰
            fov: è§†åœºè§’ï¼ˆåº¦ï¼‰
            near_plane: è¿‘å¹³é¢è·ç¦»ï¼ˆç±³ï¼‰
            far_plane: è¿œå¹³é¢è·ç¦»ï¼ˆç±³ï¼‰
        """
        self.robot_id = robot_id
        self.sensor_link_id = sensor_link_id
        self.image_width = image_width
        self.image_height = image_height
        self.fov = fov
        self.near_plane = near_plane
        self.far_plane = far_plane
        
        # ==========================================
        # Extrinsic Calibrationï¼ˆå¤–å‚æ ‡å®šï¼‰
        # ==========================================
        # å®šä¹‰ç›¸æœºåœ¨ä¼ æ„Ÿå™¨linkåæ ‡ç³»ä¸­çš„ç›¸å¯¹ä½ç½®å’Œå§¿æ€
        # è¿™äº›å‚æ•°éœ€è¦æ ¹æ®å®é™…çš„æœºå™¨äººé…ç½®è¿›è¡Œæ ‡å®š
        
        # ç›¸æœºç›¸å¯¹äºæœ«ç«¯æ‰§è¡Œå™¨çš„å¹³ç§»ï¼ˆç±³ï¼‰
        # å‡è®¾ç›¸æœºå®‰è£…åœ¨æœ«ç«¯æ‰§è¡Œå™¨å‰æ–¹ç¨å¾®åä¸‹çš„ä½ç½®
        self.camera_offset_position = np.array([0.0, 0.0, 0.0])  # [x, y, z]
        
        # ç›¸æœºç›¸å¯¹äºæœ«ç«¯æ‰§è¡Œå™¨çš„æ—‹è½¬ï¼ˆæ¬§æ‹‰è§’ï¼Œå¼§åº¦ï¼‰
        # å‡è®¾ç›¸æœºæœå‘ä¸æœ«ç«¯æ‰§è¡Œå™¨ä¸€è‡´ï¼Œç¨å¾®å‘ä¸‹å€¾æ–œ
        self.camera_offset_orientation = np.array([0.0, 0.0, 0.0])  # [roll, pitch, yaw]
        
        # è®¡ç®—æŠ•å½±çŸ©é˜µï¼ˆåªéœ€è®¡ç®—ä¸€æ¬¡ï¼‰
        self.projection_matrix = self._compute_projection_matrix()
        
        print(f"[æ·±åº¦ç›¸æœº] åˆå§‹åŒ–å®Œæˆ")
        print(f"  åˆ†è¾¨ç‡: {image_width}x{image_height}")
        print(f"  è§†åœºè§’: {fov}Â°")
        print(f"  æ·±åº¦èŒƒå›´: {near_plane}m - {far_plane}m")
    
    def _compute_projection_matrix(self) -> List[float]:
        """
        è®¡ç®—ç›¸æœºæŠ•å½±çŸ©é˜µ
        
        Returns:
            æŠ•å½±çŸ©é˜µï¼ˆ4x4ï¼‰
        """
        aspect = self.image_width / self.image_height
        projection_matrix = p.computeProjectionMatrixFOV(
            fov=self.fov,
            aspect=aspect,
            nearVal=self.near_plane,
            farVal=self.far_plane
        )
        return projection_matrix
    
    def get_camera_pose_in_world(self) -> Tuple[np.ndarray, np.ndarray]:
        """
        è·å–ç›¸æœºåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„ä½ç½®å’Œå§¿æ€
        è¿™æ˜¯å¤–å‚æ ‡å®šçš„æ ¸å¿ƒï¼šä»æœºå™¨äººlinkçŠ¶æ€æ¨ç®—ç›¸æœºä½ç½®
        
        Returns:
            Tuple[ç›¸æœºä½ç½®(3,), ç›¸æœºå§¿æ€å››å…ƒæ•°(4,)]
        """
        # 1. è·å–ä¼ æ„Ÿå™¨linkåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„çŠ¶æ€
        link_state = p.getLinkState(
            self.robot_id, 
            self.sensor_link_id,
            computeForwardKinematics=True
        )
        link_pos_world = np.array(link_state[0])  # ä½ç½®
        link_orn_world = np.array(link_state[1])  # å››å…ƒæ•°æ–¹å‘
        
        # 2. åº”ç”¨ç›¸æœºçš„å¤–å‚æ ‡å®šï¼ˆç›¸æœºç›¸å¯¹äºlinkçš„åç§»ï¼‰
        # æ—‹è½¬åç§» - ä½¿ç”¨å››å…ƒæ•°ä¹˜æ³•ç»„åˆæ—‹è½¬
        camera_offset_quat = p.getQuaternionFromEuler(self.camera_offset_orientation)
        
        # å››å…ƒæ•°ä¹˜æ³•: q_world = q_link * q_offset
        camera_orn_world = np.array(p.multiplyTransforms(
            [0, 0, 0], link_orn_world.tolist(),      # linkçš„å§¿æ€
            [0, 0, 0], camera_offset_quat            # ç›¸æœºåç§»
        )[1])  # åªå–å››å…ƒæ•°éƒ¨åˆ†ï¼Œè½¬ä¸ºnumpyæ•°ç»„
        
        # å¹³ç§»åç§»ï¼ˆè€ƒè™‘linkçš„æ—‹è½¬ï¼‰
        link_rot_matrix = np.array(p.getMatrixFromQuaternion(link_orn_world)).reshape(3, 3)
        camera_pos_world = link_pos_world + link_rot_matrix @ self.camera_offset_position
        
        return camera_pos_world, camera_orn_world
    
    def capture_depth_image(self) -> Tuple[np.ndarray, np.ndarray]:
        """
        æ•è·æ·±åº¦å›¾åƒ
        
        Returns:
            Tuple[depth_buffer(H, W), rgb_image(H, W, 3)]
        """
        # è·å–ç›¸æœºåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„ä½ç½®å’Œå§¿æ€
        camera_pos, camera_orn = self.get_camera_pose_in_world()
        
        # å°†å››å…ƒæ•°è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
        camera_rot_matrix = np.array(p.getMatrixFromQuaternion(camera_orn)).reshape(3, 3)
        
        # è®¡ç®—ç›¸æœºçš„å‰æ–¹å‘ï¼ˆé€šå¸¸æ˜¯-Zè½´ï¼‰å’Œä¸Šæ–¹å‘ï¼ˆé€šå¸¸æ˜¯Yè½´ï¼‰
        camera_forward = camera_rot_matrix @ np.array([0, 0, -1])
        camera_up = camera_rot_matrix @ np.array([0, 1, 0])
        
        # è®¡ç®—ç›®æ ‡ç‚¹ï¼ˆç›¸æœºæœå‘çš„ç‚¹ï¼‰
        target_pos = camera_pos + camera_forward * 1.0
        
        # è®¡ç®—è§†å›¾çŸ©é˜µ
        view_matrix = p.computeViewMatrix(
            cameraEyePosition=camera_pos.tolist(),
            cameraTargetPosition=target_pos.tolist(),
            cameraUpVector=camera_up.tolist()
        )
        
        # è·å–ç›¸æœºå›¾åƒï¼ˆRGB + Depthï¼‰
        width, height, rgb_img, depth_buffer, seg_img = p.getCameraImage(
            width=self.image_width,
            height=self.image_height,
            viewMatrix=view_matrix,
            projectionMatrix=self.projection_matrix,
            renderer=p.ER_TINY_RENDERER  # ä½¿ç”¨å¿«é€Ÿæ¸²æŸ“å™¨
        )
        
        # å°†RGBå›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
        rgb_array = np.array(rgb_img).reshape(height, width, 4)[:, :, :3]
        
        # å°†æ·±åº¦ç¼“å†²åŒºè½¬æ¢ä¸ºnumpyæ•°ç»„
        depth_array = np.array(depth_buffer).reshape(height, width)
        
        return depth_array, rgb_array
    
    def depth_buffer_to_distance(self, depth_buffer: np.ndarray) -> np.ndarray:
        """
        å°†æ·±åº¦ç¼“å†²åŒºå€¼è½¬æ¢ä¸ºå®é™…è·ç¦»ï¼ˆç±³ï¼‰
        
        PyBulletçš„æ·±åº¦ç¼“å†²åŒºæ˜¯å½’ä¸€åŒ–çš„éçº¿æ€§å€¼ï¼Œéœ€è¦è½¬æ¢
        
        Args:
            depth_buffer: æ·±åº¦ç¼“å†²åŒºæ•°ç»„ (H, W)ï¼Œå€¼åœ¨[0, 1]
            
        Returns:
            è·ç¦»æ•°ç»„ (H, W)ï¼Œå•ä½ï¼šç±³
        """
        # PyBulletæ·±åº¦ç¼“å†²åŒºå…¬å¼ï¼š
        # depth = far * near / (far - (far - near) * depth_buffer)
        distance = self.far_plane * self.near_plane / (
            self.far_plane - (self.far_plane - self.near_plane) * depth_buffer
        )
        return distance


class OccupancyDetector:
    """
    å ç”¨æ£€æµ‹å™¨
    å°†æ·±åº¦å›¾åƒè½¬æ¢ä¸º3Dç©ºé—´ä¸­çš„éšœç¢ç‰©ä½ç½®
    """
    
    def __init__(self, depth_camera: DepthCamera):
        """
        åˆå§‹åŒ–å ç”¨æ£€æµ‹å™¨
        
        Args:
            depth_camera: æ·±åº¦ç›¸æœºå®ä¾‹
        """
        self.camera = depth_camera
        
        # é¢„è®¡ç®—åƒç´ åæ ‡ç½‘æ ¼ï¼ˆæé«˜æ•ˆç‡ï¼‰
        self.pixel_coords = self._create_pixel_grid()
        
        print(f"[å ç”¨æ£€æµ‹å™¨] åˆå§‹åŒ–å®Œæˆ")
    
    def _create_pixel_grid(self) -> np.ndarray:
        """
        åˆ›å»ºåƒç´ åæ ‡ç½‘æ ¼
        
        Returns:
            åƒç´ åæ ‡æ•°ç»„ (H, W, 2)ï¼Œå­˜å‚¨æ¯ä¸ªåƒç´ çš„(u, v)åæ ‡
        """
        u_coords = np.arange(self.camera.image_width)
        v_coords = np.arange(self.camera.image_height)
        u_grid, v_grid = np.meshgrid(u_coords, v_coords)
        pixel_coords = np.stack([u_grid, v_grid], axis=-1)
        return pixel_coords
    
    def depth_to_point_cloud(self, 
                            depth_distance: np.ndarray,
                            camera_pos: np.ndarray,
                            camera_orn: np.ndarray) -> np.ndarray:
        """
        å°†æ·±åº¦å›¾åƒè½¬æ¢ä¸º3Dç‚¹äº‘ï¼ˆä¸–ç•Œåæ ‡ç³»ï¼‰
        
        Args:
            depth_distance: æ·±åº¦è·ç¦»æ•°ç»„ (H, W)
            camera_pos: ç›¸æœºåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„ä½ç½® (3,)
            camera_orn: ç›¸æœºåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„å§¿æ€ï¼ˆå››å…ƒæ•°ï¼‰ (4,)
            
        Returns:
            ç‚¹äº‘æ•°ç»„ (N, 3)ï¼Œä¸–ç•Œåæ ‡ç³»ä¸­çš„3Dç‚¹
        """
        H, W = depth_distance.shape
        
        # ç›¸æœºå†…å‚ï¼ˆä»FOVè®¡ç®—ï¼‰
        focal_length = (W / 2.0) / np.tan(np.deg2rad(self.camera.fov / 2.0))
        cx = W / 2.0
        cy = H / 2.0
        
        # è·å–æ‰€æœ‰åƒç´ åæ ‡
        u = self.pixel_coords[:, :, 0]
        v = self.pixel_coords[:, :, 1]
        
        # åæŠ•å½±åˆ°ç›¸æœºåæ ‡ç³»
        # ç›¸æœºåæ ‡ç³»ï¼šXå³ï¼ŒYä¸‹ï¼ŒZå‰
        z_cam = depth_distance
        x_cam = (u - cx) * z_cam / focal_length
        y_cam = (v - cy) * z_cam / focal_length
        
        # ç»„åˆä¸ºç›¸æœºåæ ‡ç³»ä¸­çš„ç‚¹ (H, W, 3)
        points_cam = np.stack([x_cam, y_cam, z_cam], axis=-1)
        
        # é‡å¡‘ä¸º (H*W, 3)
        points_cam_flat = points_cam.reshape(-1, 3)
        
        # è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»
        camera_rot_matrix = np.array(p.getMatrixFromQuaternion(camera_orn)).reshape(3, 3)
        points_world = (camera_rot_matrix @ points_cam_flat.T).T + camera_pos
        
        return points_world
    
    def detect_obstacles_from_point_cloud(self,
                                         point_cloud: np.ndarray,
                                         ignore_ids: set,
                                         voxel_size: float = 0.05,
                                         min_points_threshold: int = 10,
                                         max_z_height: float = 1.5,
                                         min_z_height: float = 0.02,
                                         tray_position: Optional[np.ndarray] = None,
                                         tray_size: Optional[np.ndarray] = None,
                                         gripper_position: Optional[np.ndarray] = None) -> List[Tuple[int, np.ndarray, np.ndarray]]:
        """
        ä»ç‚¹äº‘ä¸­æ£€æµ‹éšœç¢ç‰©å ç”¨
        
        ä½¿ç”¨ä½“ç´ åŒ–(voxelization)æ–¹æ³•ç®€åŒ–ç‚¹äº‘ï¼Œç„¶åè¿›è¡Œç©ºé—´èšç±»
        
        Args:
            point_cloud: ç‚¹äº‘ (N, 3) - ä¸–ç•Œåæ ‡ç³»ä¸­çš„3Dç‚¹
            ignore_ids: è¦å¿½ç•¥çš„ç‰©ä½“IDï¼ˆç”¨äºç¡®å®šæ˜¯å¦éœ€è¦è¿‡æ»¤å¤¹çˆªåŒºåŸŸï¼‰
            voxel_size: ä½“ç´ å¤§å°ï¼ˆç±³ï¼‰
            min_points_threshold: æœ€å°ç‚¹æ•°é˜ˆå€¼ï¼Œå°‘äºæ­¤æ•°é‡çš„ç°‡ä¼šè¢«è¿‡æ»¤
            max_z_height: æœ€å¤§é«˜åº¦é˜ˆå€¼ï¼ˆè¿‡æ»¤å¤©èŠ±æ¿ç­‰ï¼‰
            min_z_height: æœ€å°é«˜åº¦é˜ˆå€¼ï¼ˆè¿‡æ»¤åœ°é¢ï¼‰
            tray_position: æ‰˜ç›˜ä½ç½® [x, y, z]ï¼ˆå¯é€‰ï¼‰
            tray_size: æ‰˜ç›˜å°ºå¯¸ [length, width, height]ï¼ˆå¯é€‰ï¼‰
            gripper_position: å¤¹çˆªä½ç½® [x, y, z]ï¼ˆå¯é€‰ï¼Œç”¨äºè¿‡æ»¤è¢«æŠ“å–ç‰©å“ï¼‰
            
        Returns:
            éšœç¢ç‰©åˆ—è¡¨: [(obs_id, position, velocity), ...]
            æ³¨æ„ï¼šobs_idä¸ºè™šæ‹ŸIDï¼ˆä»1å¼€å§‹ï¼‰ï¼Œvelocityä¸ºé›¶å‘é‡ï¼ˆç‚¹äº‘æ— æ³•ç›´æ¥è·å–é€Ÿåº¦ï¼‰
        """
        # 1. è¿‡æ»¤æ— æ•ˆç‚¹ï¼ˆè¶…å‡ºèŒƒå›´çš„ç‚¹ï¼‰
        valid_mask = (
            (point_cloud[:, 2] > min_z_height) &  # é«˜äºåœ°é¢
            (point_cloud[:, 2] < max_z_height) &  # ä½äºå¤©èŠ±æ¿
            (np.abs(point_cloud[:, 0]) < 2.0) &   # XèŒƒå›´åˆç†
            (np.abs(point_cloud[:, 1]) < 2.0) &   # YèŒƒå›´åˆç†
            (~np.isnan(point_cloud).any(axis=1)) & # æ— NaN
            (~np.isinf(point_cloud).any(axis=1))   # æ— Inf
        )
        
        # ğŸ”¥ 2. è¿‡æ»¤å¤¹çˆªé™„è¿‘çš„ç‚¹äº‘ï¼ˆè¢«æŠ“å–çš„ç‰©å“ï¼‰
        # å¦‚æœæä¾›äº†å¤¹çˆªä½ç½®ä¸”ignore_idsä¸ä¸ºç©ºï¼ˆè¯´æ˜æœ‰è¢«æŠ“å–çš„ç‰©å“ï¼‰ï¼Œåˆ™è¿‡æ»¤å¤¹çˆªé™„è¿‘çš„ç‚¹
        if gripper_position is not None and len(ignore_ids) > 0:
            # è®¡ç®—æ¯ä¸ªç‚¹åˆ°å¤¹çˆªçš„è·ç¦»
            distances_to_gripper = np.linalg.norm(point_cloud - gripper_position, axis=1)
            # è¿‡æ»¤æ‰è·ç¦»å¤¹çˆª15cmä»¥å†…çš„ç‚¹ï¼ˆè¢«æŠ“å–çš„ç‰©å“é€šå¸¸åœ¨è¿™ä¸ªèŒƒå›´å†…ï¼‰
            gripper_radius = 0.15
            is_not_near_gripper = distances_to_gripper > gripper_radius
            valid_mask = valid_mask & is_not_near_gripper
        
        # 3. è¿‡æ»¤æ‰˜ç›˜åº•éƒ¨ï¼ˆåªä¿ç•™æ‰˜ç›˜çš„å››å£ï¼‰
        if tray_position is not None and tray_size is not None:
            # æ‰˜ç›˜çš„è¾¹ç•Œ
            tray_x_min = tray_position[0] - tray_size[0] / 2
            tray_x_max = tray_position[0] + tray_size[0] / 2
            tray_y_min = tray_position[1] - tray_size[1] / 2
            tray_y_max = tray_position[1] + tray_size[1] / 2
            tray_z_max = tray_position[2] + tray_size[2]
            
            # å®šä¹‰æ‰˜ç›˜å†…éƒ¨åŒºåŸŸï¼ˆç¼©å°è¾¹ç•Œï¼Œç•™å‡ºè¾¹ç¼˜ï¼‰
            # è¾¹ç¼˜åšåº¦çº¦5cmï¼Œè¿™æ ·æ‰˜ç›˜çš„å››å£ä¼šè¢«ä¿ç•™
            edge_thickness = 0.05
            inner_x_min = tray_x_min + edge_thickness
            inner_x_max = tray_x_max - edge_thickness
            inner_y_min = tray_y_min + edge_thickness
            inner_y_max = tray_y_max - edge_thickness
            
            # è¯†åˆ«æ‰˜ç›˜åº•éƒ¨çš„ç‚¹ï¼ˆåœ¨æ‰˜ç›˜å†…éƒ¨ä¸”é«˜åº¦è¾ƒä½ï¼‰
            is_inside_tray = (
                (point_cloud[:, 0] > inner_x_min) &
                (point_cloud[:, 0] < inner_x_max) &
                (point_cloud[:, 1] > inner_y_min) &
                (point_cloud[:, 1] < inner_y_max) &
                (point_cloud[:, 2] < tray_z_max + 0.02)  # æ‰˜ç›˜é«˜åº¦+2cmä»¥å†…
            )
            
            # è¿‡æ»¤æ‰æ‰˜ç›˜åº•éƒ¨çš„ç‚¹ï¼ˆä¿ç•™æ‰˜ç›˜è¾¹ç¼˜å’Œå…¶ä»–éšœç¢ç‰©ï¼‰
            valid_mask = valid_mask & ~is_inside_tray
        
        filtered_points = point_cloud[valid_mask]
        
        if len(filtered_points) < min_points_threshold:
            return []
        
        # 2. ä½“ç´ åŒ– - å°†ç‚¹äº‘é™é‡‡æ ·åˆ°è§„åˆ™ç½‘æ ¼
        # è®¡ç®—æ¯ä¸ªç‚¹å±äºå“ªä¸ªä½“ç´ 
        voxel_indices = np.floor(filtered_points / voxel_size).astype(np.int32)
        
        # ä½¿ç”¨å­—å…¸å­˜å‚¨æ¯ä¸ªä½“ç´ ä¸­çš„ç‚¹
        voxel_dict = {}
        for i, voxel_idx in enumerate(voxel_indices):
            key = tuple(voxel_idx)
            if key not in voxel_dict:
                voxel_dict[key] = []
            voxel_dict[key].append(filtered_points[i])
        
        # 3. è®¡ç®—æ¯ä¸ªä½“ç´ çš„ä¸­å¿ƒç‚¹
        voxel_centers = []
        for voxel_points in voxel_dict.values():
            if len(voxel_points) >= 2:  # è‡³å°‘2ä¸ªç‚¹æ‰è®¤ä¸ºæ˜¯æœ‰æ•ˆä½“ç´ 
                center = np.mean(voxel_points, axis=0)
                voxel_centers.append(center)
        
        if len(voxel_centers) == 0:
            return []
        
        voxel_centers = np.array(voxel_centers)
        
        # 4. ç®€å•çš„ç©ºé—´èšç±» - åŸºäºè·ç¦»çš„è¿é€šæ€§
        # ä½¿ç”¨DBSCANæ€æƒ³ï¼Œä½†ç®€åŒ–å®ç°
        clusters = self._simple_spatial_clustering(
            voxel_centers, 
            eps=voxel_size * 3,  # èšç±»è·ç¦»é˜ˆå€¼
            min_samples=min_points_threshold // 5  # æœ€å°‘ä½“ç´ æ•°
        )
        
        # 5. ä¸ºæ¯ä¸ªç°‡ç”Ÿæˆéšœç¢ç‰©ä¿¡æ¯
        obstacles = []
        obs_id_counter = 1
        
        for cluster_points in clusters:
            if len(cluster_points) >= 3:  # è‡³å°‘3ä¸ªä½“ç´ 
                # è®¡ç®—ç°‡çš„ä¸­å¿ƒä½œä¸ºéšœç¢ç‰©ä½ç½®
                obstacle_center = np.mean(cluster_points, axis=0)
                
                # é€Ÿåº¦è®¾ä¸ºé›¶ï¼ˆç‚¹äº‘æ— æ³•ç›´æ¥æµ‹é‡é€Ÿåº¦ï¼‰
                velocity = np.array([0.0, 0.0, 0.0])
                
                # æ·»åŠ åˆ°éšœç¢ç‰©åˆ—è¡¨
                # æ ¼å¼: (obs_id, position, velocity)
                obstacles.append((obs_id_counter, obstacle_center, velocity))
                obs_id_counter += 1
        
        return obstacles
    
    def _simple_spatial_clustering(self, 
                                   points: np.ndarray, 
                                   eps: float, 
                                   min_samples: int) -> List[np.ndarray]:
        """
        ç®€å•çš„ç©ºé—´èšç±»ç®—æ³•ï¼ˆç±»DBSCANï¼‰
        
        Args:
            points: ç‚¹äº‘ (N, 3)
            eps: é‚»åŸŸåŠå¾„
            min_samples: æœ€å°æ ·æœ¬æ•°
            
        Returns:
            ç°‡åˆ—è¡¨ï¼Œæ¯ä¸ªç°‡æ˜¯ä¸€ä¸ªç‚¹æ•°ç»„
        """
        n_points = len(points)
        if n_points == 0:
            return []
        
        # æ ‡è®°æ¯ä¸ªç‚¹æ˜¯å¦å·²è¢«è®¿é—®
        visited = np.zeros(n_points, dtype=bool)
        # æ ‡è®°æ¯ä¸ªç‚¹å±äºå“ªä¸ªç°‡ï¼ˆ-1è¡¨ç¤ºå™ªå£°ï¼‰
        labels = np.full(n_points, -1, dtype=np.int32)
        
        cluster_id = 0
        
        for i in range(n_points):
            if visited[i]:
                continue
            
            visited[i] = True
            
            # æ‰¾åˆ°å½“å‰ç‚¹çš„é‚»å±…
            distances = np.linalg.norm(points - points[i], axis=1)
            neighbors = np.where(distances < eps)[0]
            
            if len(neighbors) < min_samples:
                # å™ªå£°ç‚¹
                labels[i] = -1
            else:
                # å¼€å§‹æ–°ç°‡
                labels[i] = cluster_id
                
                # æ‰©å±•ç°‡
                seed_set = list(neighbors)
                j = 0
                while j < len(seed_set):
                    neighbor_idx = seed_set[j]
                    
                    if not visited[neighbor_idx]:
                        visited[neighbor_idx] = True
                        
                        # æ‰¾é‚»å±…çš„é‚»å±…
                        neighbor_distances = np.linalg.norm(points - points[neighbor_idx], axis=1)
                        neighbor_neighbors = np.where(neighbor_distances < eps)[0]
                        
                        if len(neighbor_neighbors) >= min_samples:
                            seed_set.extend(neighbor_neighbors.tolist())
                    
                    if labels[neighbor_idx] == -1:
                        labels[neighbor_idx] = cluster_id
                    
                    j += 1
                
                cluster_id += 1
        
        # ç»„ç»‡æˆç°‡åˆ—è¡¨
        clusters = []
        for cid in range(cluster_id):
            cluster_mask = (labels == cid)
            if np.sum(cluster_mask) > 0:
                clusters.append(points[cluster_mask])
        
        return clusters


class DepthPerceptionSystem:
    """
    æ·±åº¦æ„ŸçŸ¥ç³»ç»Ÿï¼ˆä¸»æ¥å£ï¼‰
    æ•´åˆæ·±åº¦ç›¸æœºå’Œå ç”¨æ£€æµ‹
    """
    
    def __init__(self,
                 robot_id: int,
                 sensor_link_id: int,
                 image_width: int = 128,
                 image_height: int = 128,
                 tray_position: Optional[np.ndarray] = None,
                 tray_size: Optional[np.ndarray] = None):
        """
        åˆå§‹åŒ–æ·±åº¦æ„ŸçŸ¥ç³»ç»Ÿ
        
        Args:
            robot_id: æœºå™¨äººID
            sensor_link_id: ä¼ æ„Ÿå™¨link ID
            image_width: å›¾åƒå®½åº¦
            image_height: å›¾åƒé«˜åº¦
            tray_position: æ‰˜ç›˜ä½ç½® [x, y, z]ï¼ˆå¯é€‰ï¼‰
            tray_size: æ‰˜ç›˜å°ºå¯¸ [length, width, height]ï¼ˆå¯é€‰ï¼‰
        """
        self.robot_id = robot_id
        self.sensor_link_id = sensor_link_id
        
        # æ‰˜ç›˜ä¿¡æ¯ï¼ˆç”¨äºè¿‡æ»¤æ‰˜ç›˜åº•éƒ¨ï¼‰
        self.tray_position = tray_position if tray_position is not None else np.array([0.5, 0.5, 0.0])
        self.tray_size = tray_size if tray_size is not None else np.array([0.4, 0.3, 0.05])  # é»˜è®¤æ‰˜ç›˜å°ºå¯¸
        
        # åˆå§‹åŒ–æ·±åº¦ç›¸æœº
        self.depth_camera = DepthCamera(
            robot_id=robot_id,
            sensor_link_id=sensor_link_id,
            image_width=image_width,
            image_height=image_height
        )
        
        # åˆå§‹åŒ–å ç”¨æ£€æµ‹å™¨
        self.occupancy_detector = OccupancyDetector(self.depth_camera)
        
        print(f"[æ·±åº¦æ„ŸçŸ¥ç³»ç»Ÿ] åˆå§‹åŒ–å®Œæˆ")
        print(f"  æ‰˜ç›˜ä½ç½®: {self.tray_position}")
        print(f"  æ‰˜ç›˜å°ºå¯¸: {self.tray_size}")
    
    def perceive_with_depth(self,
                           ignore_ids: Optional[set] = None,
                           debug: bool = False) -> Dict:
        """
        ä½¿ç”¨æ·±åº¦æ„ŸçŸ¥è·å–éšœç¢ç‰©ä¿¡æ¯
        
        Args:
            ignore_ids: è¦å¿½ç•¥çš„ç‰©ä½“ID
            debug: æ˜¯å¦æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
            
        Returns:
            æ„ŸçŸ¥ç»“æœå­—å…¸: {
                'current_obstacles': [(obs_id, position, velocity), ...],
                'predicted_obstacles': [(obs_id, predicted_position, confidence), ...],
                'depth_image': depth_array,
                'point_cloud': point_cloud_array
            }
        """
        if ignore_ids is None:
            ignore_ids = set()
        
        # 1. æ•è·æ·±åº¦å›¾åƒ
        depth_buffer, rgb_image = self.depth_camera.capture_depth_image()
        
        # 2. è½¬æ¢ä¸ºè·ç¦»
        depth_distance = self.depth_camera.depth_buffer_to_distance(depth_buffer)
        
        # 3. è·å–ç›¸æœºä½å§¿
        camera_pos, camera_orn = self.depth_camera.get_camera_pose_in_world()
        
        # 4. è½¬æ¢ä¸ºç‚¹äº‘
        point_cloud = self.occupancy_detector.depth_to_point_cloud(
            depth_distance, camera_pos, camera_orn
        )
        
        # ğŸ”¥ 5. è·å–å¤¹çˆªä½ç½®ï¼ˆç”¨äºè¿‡æ»¤è¢«æŠ“å–çš„ç‰©å“ï¼‰
        # å¦‚æœignore_idsä¸ä¸ºç©ºï¼Œè¯´æ˜æœ‰ç‰©å“è¢«æŠ“å–ï¼Œéœ€è¦è·å–å¤¹çˆªä½ç½®
        gripper_position = None
        if len(ignore_ids) > 0:
            try:
                # è·å–æœ«ç«¯æ‰§è¡Œå™¨ï¼ˆå¤¹çˆªï¼‰çš„ä½ç½®
                ee_state = p.getLinkState(
                    self.robot_id, 
                    self.sensor_link_id,
                    computeForwardKinematics=True
                )
                gripper_position = np.array(ee_state[0])
            except Exception as e:
                if debug:
                    print(f"  [æ·±åº¦æ„ŸçŸ¥] æ— æ³•è·å–å¤¹çˆªä½ç½®: {e}")
        
        # 6. æ£€æµ‹éšœç¢ç‰©ï¼ˆä¼ é€’æ‰˜ç›˜ä¿¡æ¯å’Œå¤¹çˆªä½ç½®ä»¥è¿‡æ»¤ï¼‰
        current_obstacles = self.occupancy_detector.detect_obstacles_from_point_cloud(
            point_cloud, ignore_ids,
            tray_position=self.tray_position,
            tray_size=self.tray_size,
            gripper_position=gripper_position
        )
        
        # 7. é¢„æµ‹æœªæ¥ä½ç½®ï¼ˆæš‚æ—¶è¿”å›ç©ºï¼‰
        predicted_obstacles = []
        
        if debug:
            print(f"  [æ·±åº¦æ„ŸçŸ¥] æ•è·æ·±åº¦å›¾åƒ: {depth_buffer.shape}")
            print(f"  [æ·±åº¦æ„ŸçŸ¥] ç”Ÿæˆç‚¹äº‘: {point_cloud.shape[0]} ä¸ªç‚¹")
            if gripper_position is not None:
                print(f"  [æ·±åº¦æ„ŸçŸ¥] ğŸ”¥ å·²è¿‡æ»¤å¤¹çˆªé™„è¿‘15cmèŒƒå›´å†…çš„ç‚¹äº‘ï¼ˆè¢«æŠ“å–ç‰©å“ï¼‰")
            print(f"  [æ·±åº¦æ„ŸçŸ¥] æ£€æµ‹åˆ° {len(current_obstacles)} ä¸ªéšœç¢ç‰©")
        
        return {
            'current_obstacles': current_obstacles,
            'predicted_obstacles': predicted_obstacles,
            'depth_image': depth_distance,
            'point_cloud': point_cloud
        }

